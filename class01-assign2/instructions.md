## Task 1: Python Web Scraping

This task tests your understanding of the Python language by applying it to a specific, well-defined task of web scraping.

### Objective
Create a Python script for enabling web scraping.

- **Input**: URL (medium article)
- **Output**: File stored on your local machine with the text from the URL

### Submission Files
- `.txt` and `.py` file

### Required Libraries
- `os` - For file storing in the local directory of your machine.
- `requests` - Used for sending requests with URL as input and getting HTML source as a response.
- `beautifulSoup` - Used in parsing HTML source response. [BeautifulSoup Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)

### Steps to Complete This Task
1. **Import Library**: Study the library usage in its documentation.
2. **Script Development**: Fill in the blank provided in the Script. Write your code between `Code goes here` and `Code ends here` comments.
3. **Run the Script**: Use the given URL of a Medium article.
4. **Output Generation**: By running the script, a new folder called `scraped_articles` will be created on your local machine.
5. **Submission**: Find the `.txt` file and upload that as the submission file along with your Python file.

## Task 2: GitHub PR of Three Files

This task involves replicating the answer from Task 1 into a Python Notebook file and creating a Pull Request (PR) on GitHub.

### Objective
- Replicate Task 1's answer into a Python Notebook (.ipynb) file.

### Submission Requirements
1. **Files for PR**:
   - `.py` file from Task 1
   - `.txt` file from Task 1
   - `.ipynb` Python Notebook file
2. **Create a PR**:
   - Designate one of your classmates as a reviewer.
3. **Submit the Link**:
   - Provide the link of your pushed repository.

### Additional Information
- Further details can be found in the supplementary files.

### Conclusion
All the best and have fun learning!